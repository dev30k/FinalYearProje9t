{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 11:16:09.523035: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 11:16:09.575981: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 11:16:09.577004: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 11:16:10.748124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = \"/home/second/Desktop/TB_Chest_Radiography_Database\"\n",
    "normal = \"/home/second/Desktop/TB_Chest_Radiography_Database/Normal/\"\n",
    "tuberculosis = \"/home/second/Desktop/TB_Chest_Radiography_Database/Tuberculosis/\"\n",
    "\n",
    "df_norm = pd.read_excel(\"/home/second/Desktop/TB_Chest_Radiography_Database/Normal.metadata.xlsx\")\n",
    "df_tub = pd.read_excel(\"/home/second/Desktop/TB_Chest_Radiography_Database/Tuberculosis.metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6626/2192205160.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  df_norm['Tuberculosis'] = np.float(0)\n",
      "/tmp/ipykernel_6626/2192205160.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  df_tub['Tuberculosis'] = np.float(1)\n"
     ]
    }
   ],
   "source": [
    "df_norm['Tuberculosis'] = np.float(0)\n",
    "df_tub['Tuberculosis'] = np.float(1)\n",
    "df_norm.drop(columns = ['FORMAT', 'SIZE', 'URL'], inplace = True)\n",
    "df_tub.drop(columns = ['FORMAT', 'SIZE', 'URL'], inplace = True)\n",
    "df = pd.concat([df_norm, df_tub])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'FILE NAME':'Image'}, inplace = True)\n",
    "label = ['Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no. of tuberculosis images :\" ,len(os.listdir(tuberculosis)))\n",
    "print(\"\\nno. of normal images :\" ,len(os.listdir(normal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(100)\n",
    "np.random.seed(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(main, 'train')\n",
    "test_dir = os.path.join(main, 'test')\n",
    "validation_dir = os.path.join(main, 'validation')\n",
    "\n",
    "if not os.path.exists(main):\n",
    "    os.mkdir(main)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "if os.path.exists(validation_dir) or os.path.exists(main) or os.path.exists(train_dir):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/train/Normal\"\n",
    "train_tub_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/train/Tuberculosis\"\n",
    "\n",
    "val_norm_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/validation/Normal\"\n",
    "val_tub_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/validation/Tuberculosis\"\n",
    "\n",
    "test_norm_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/test/Normal\"\n",
    "test_tub_dir = \"/home/second/Desktop/TB_Chest_Radiography_Database/test/Tuberculosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = [\"Normal\", \"Tuberculosis\"]\n",
    "image_size = 520\n",
    "\n",
    "train_percentage = 0.8\n",
    "test_percentage = 0.1\n",
    "validation_percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(normal_dir, tub_dr ,df):\n",
    "    df_fn_n = os.listdir(normal_dir)\n",
    "    df_fn_tb = os.listdir(tub_dr)\n",
    "\n",
    "    df_fn = df_fn_tb + df_fn_n\n",
    "    df_ext = []\n",
    "    for fn in df_fn:\n",
    "        df_ext.append(fn[:-4])\n",
    "    df_res = df[df['Image'].isin(df_ext)]\n",
    "    \n",
    "    return df_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_df(train_norm_dir,train_tub_dir,df)\n",
    "test_df = create_df(test_norm_dir,test_tub_dir,df)\n",
    "val_df = create_df(val_norm_dir,val_tub_dir,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Image'] = train_df['Image'] + '.png'\n",
    "val_df['Image'] = val_df['Image'] + '.png'\n",
    "test_df['Image'] = test_df['Image'] + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape[0] + val_df.shape[0] + test_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for cat in Labels:\n",
    "    cat_dir = os.path.join(main,cat)\n",
    "\n",
    "    os.makedirs(os.path.join(train_dir, cat))\n",
    "    os.makedirs(os.path.join(test_dir, cat))\n",
    "    os.makedirs(os.path.join(validation_dir, cat))\n",
    "\n",
    "    image_files = [f for f in os.listdir(cat_dir) if f.endswith('.png')]\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * train_percentage)\n",
    "    num_test = int(num_images * test_percentage)\n",
    "    num_validation = num_images - num_train - num_test\n",
    "\n",
    "    train_files = image_files[:num_train]\n",
    "    test_files = image_files[num_train:num_train+num_test]\n",
    "    validation_files = image_files[num_train+num_test:]\n",
    "\n",
    "    for filename in train_files:\n",
    "        src = os.path.join(cat_dir, filename)\n",
    "        dst = os.path.join(train_dir, cat, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for filename in test_files:\n",
    "        src = os.path.join(cat_dir, filename)\n",
    "        dst = os.path.join(test_dir, cat, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for filename in validation_files:\n",
    "        src = os.path.join(cat_dir, filename)\n",
    "        dst = os.path.join(validation_dir, cat, filename)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_gen(df,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# imageDataGenerator = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.1,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     samplewise_center=True,\n",
    "#     samplewise_std_normalization=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = imageDataGenerator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (200, 200),\n",
    "     batch_size = 12,\n",
    "     shuffle=True,\n",
    "     class_mode = 'binary',\n",
    ")\n",
    "test_gen = imageDataGenerator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (200, 200),\n",
    "     batch_size = 12,\n",
    "     shuffle=True,\n",
    "     class_mode = 'binary',\n",
    ")\n",
    "val_gen = imageDataGenerator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (200, 200),\n",
    "     batch_size = 12,\n",
    "     shuffle=True,\n",
    "     class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_gen.classes), y=train_gen.classes)\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(name='classifier')\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(200,200,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(200,200,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=192, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=192, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.hdf5',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max', verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=len(train_gen),\n",
    "                              epochs=10,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=len(val_gen),callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image,model):\n",
    "    labels = ['Normal','Tuberculosis']\n",
    "    image = np.array(image)\n",
    "    image = image/image.max()\n",
    "    image = image.reshape(-1,200,200,3)\n",
    "    probabilities = model.predict(image).reshape(-1)\n",
    "    pred = labels[np.argmax(probabilities)]\n",
    "    return pred, {x:y for x,y in zip(labels, probabilities)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image = cv2.imread(\"/home/second/Downloads/Normal-3.png\")\n",
    "image = cv2.resize(image, (200, 200))\n",
    "pred, probabilities = predict(image, model)\n",
    "\n",
    "x = list(probabilities.keys())\n",
    "y = list(probabilities.values())\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,4), gridspec_kw={'width_ratios': [3, 4]})\n",
    "ax[0].imshow(image)\n",
    "ax[0].axis('off')\n",
    "\n",
    "bars = ax[1].barh(x, y, height=0.3, color=['#69c0cd', '#69c0cd'])\n",
    "ax[1].bar_label(bars)\n",
    "\n",
    "ax[1].set_title('Predicted Class Probabilities')\n",
    "plt.xlim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "print('Actual   :')\n",
    "print('Predicted:', pred)\n",
    "print('-'*80)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
